# Ensemble Methods 
## Bagging 
## Boosting
<p>
Ensemble learning is a machine learning paradigm
where multiple models often called weak learners are trained to solve to get better result .

Here is Main Idea to use ensemble is that weak model will work better in a combined way.

So how to combine these models.
Using Bagging and Boosting;</p>
<p>
Bagging : Is often consider homogenous learner(weak-learner) learn them independently from each other and follow some kind of averaging process.
And it is also know as Bootstrap aggregation that will produces a ensemble model that is more robust then any individual model.
</p>
- Bagging Using Random Forest
<p>
Boosting : Is also often considers homogenous weak learners,learns them sequentially (a base models depends on the previous one).Here is idea to fit models 
iteratively.
</p>
<span>Boosting Techiniques:
</span>
- Adaboost 
- Gradient Boosting 
- Xgboost









