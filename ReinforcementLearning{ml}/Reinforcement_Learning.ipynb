{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reinforcement learning is a type of machine learning where an agent learns to make sequential decisions in\n",
    "# an environment to maximize a cumulative reward. The agent interacts with the environment, \n",
    "# receives feedback in the form of rewards or punishments, \n",
    "# and uses this feedback to learn the optimal actions to take in different situations.\n",
    "\n",
    "# In reinforcement learning, the agent learns through trial and error.\n",
    "# It explores the environment by taking actions and receives feedback in the form of rewards\n",
    "# or penalties based on the outcomes of those actions. The agent's goal is to learn a policy, \n",
    "# which is a mapping from states to actions, that maximizes the long-term cumulative reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "#create Environment class\n",
    "class MyEnvironment:\n",
    "\n",
    "  def __init__(self):\n",
    "    #maximum number of steps which the agent can take to gain rewards\n",
    "    self.remaining_steps=20 #assume that the game must be completed within 20 steps\n",
    "\n",
    "  def get_observation(self):\n",
    "    #it can be any number of coordinates.Its considered as 3 here.\n",
    "    #These values -0.0,0.0,0.0 represent some kind of logic that gives\n",
    "    #  info about the environment.These values can be anything.\n",
    "    return [1.0,2.0,1.0]  \n",
    "  \n",
    "  #when agent,performs an action,it should get a reward\n",
    "  #i have set it as 1 for reward,-1 for punishment\n",
    "  def get_actions(self):\n",
    "    return [-1,1]\n",
    "\n",
    "  #if steps are completed,return True because the agent should not move anymore\n",
    "  def check_is_done(self)->bool:\n",
    "    return self.remaining_steps==0\n",
    "\n",
    "  def action(self,int):\n",
    "    if self.check_is_done():\n",
    "      raise Exception(\"Game over\")      \n",
    "    self.remaining_steps-=1  #if steps can still be taken-game not finished=>decrement the remaining number of steps\n",
    "    return random.random()  #here-as this is a simple implementation-just returning a random number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#agent implements some policy\n",
    "\n",
    "class myAgent:\n",
    "  def __init__(self):\n",
    "    self.total_rewards=0.0 #initially-agent-no rewards\n",
    "\n",
    "  def step(self,ob:MyEnvironment):\n",
    "    curr_obs=ob.get_observation()\n",
    "    print(curr_obs)\n",
    "    curr_action=ob.get_actions()\n",
    "    print(curr_action)\n",
    "    curr_reward=ob.action(random.choice(curr_action)) \n",
    "    #here,we are randomly picking -1 or 1\n",
    "    #usually,when action() is invoked,implementation to check if the decision of the agent is crt-give positive reward else negative reward\n",
    "    self.total_rewards+=curr_reward\n",
    "    print(\"Total rewards so far= %.3f \"%self.total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 0.895 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 1.116 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 2.014 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 3.006 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 3.625 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 4.489 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 5.340 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 6.047 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 6.139 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 6.734 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 7.068 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 7.813 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 8.322 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 9.220 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 9.976 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 10.697 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 11.212 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 12.055 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 13.026 \n",
      "[1.0, 2.0, 1.0]\n",
      "[-1, 1]\n",
      "Total rewards so far= 13.525 \n",
      "Total reward is 13.525 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__=='__main__':\n",
    "  obj=MyEnvironment()\n",
    "  agent=myAgent()\n",
    "  step_number=0\n",
    "\n",
    "  while not obj.check_is_done():\n",
    "    step_number+=1\n",
    "    agent.step(obj)\n",
    "    \n",
    "\n",
    "  print(\"Total reward is %.3f \"%agent.total_rewards)\n",
    "  #different o/p everytime we run this code b'coz diff random numbers will be generated\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
