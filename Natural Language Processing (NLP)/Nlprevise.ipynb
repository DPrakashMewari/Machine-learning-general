{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abb2b71-7520-4920-bdcb-ac065cea2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43938dc9-408e-43f5-82d6-c584ea70e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\" Two women were fighting over a child. “He is my child, leave him alone,” cried the lady in the red sari. The poor child was too young to speak.\n",
    "\n",
    "“No, he is mine,” cried the woman in the green sari.\n",
    "\n",
    "Soon a crowd gathered.\n",
    "\n",
    "The village elders took the quarreling women to a wise man. The village wise man asked the lady in the red sari, “What do you have to say?”\n",
    "\n",
    "“He is my child, Sir. I was bathing in the river and had left my son on the bank. This woman lifted my child and ran away. I hurriedly dressed and ran after her,” said the woman.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a130be0e-c32b-47c3-b58e-095b645cce66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Two women were fighting over a child. He is my child leave him alone cried the lady in the red sari. The poor child was too young to speak.No he is mine cried the woman in the green sari.Soon a crowd gathered.The village elders took the quarreling women to a wise man. The village wise man asked the lady in the red sari What do you have to sayHe is my child Sir. I was bathing in the river and had left my son on the bank. This woman lifted my child and ran away. I hurriedly dressed and ran after her said the woman.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex to remove all special chars:\n",
    "import re\n",
    "paragraph = re.sub(r'[^a-zA-Z. ]', '', paragraph)\n",
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81b946a0-e662-4794-bf27-dfb7098c81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization : \n",
    "\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ca3090f-f64c-4238-b2cb-889a09cd540e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Two women were fighting over a child.',\n",
       " 'He is my child leave him alone cried the lady in the red sari.',\n",
       " 'The poor child was too young to speak.No he is mine cried the woman in the green sari.Soon a crowd gathered.The village elders took the quarreling women to a wise man.',\n",
       " 'The village wise man asked the lady in the red sari What do you have to sayHe is my child Sir.',\n",
       " 'I was bathing in the river and had left my son on the bank.',\n",
       " 'This woman lifted my child and ran away.',\n",
       " 'I hurriedly dressed and ran after her said the woman.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3192a1f-6063-4be1-9029-11480edbb7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Two women were fighting over a child.', 'He is my child leave him alone cried the lady in the red sari.', 'The poor child was too young to speak.No he is mine cried the woman in the green sari.Soon a crowd gathered.The village elders took the quarreling women to a wise man.', 'The village wise man asked the lady in the red sari What do you have to sayHe is my child Sir.', 'I was bathing in the river and had left my son on the bank.', 'This woman lifted my child and ran away.', 'I hurriedly dressed and ran after her said the woman.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "text = \"Tokenization is important for NLP.\"\n",
    "tokens = sent_tokenize(paragraph)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bfa110af-728a-4bf5-ab86-844e34597c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Two women were fighting over a child.',\n",
       " 'He is my child leave him alone cried the lady in the red sari.',\n",
       " 'The poor child was too young to speak.No he is mine cried the woman in the green sari.Soon a crowd gathered.The village elders took the quarreling women to a wise man.',\n",
       " 'The village wise man asked the lady in the red sari What do you have to sayHe is my child Sir.',\n",
       " 'I was bathing in the river and had left my son on the bank.',\n",
       " 'This woman lifted my child and ran away.',\n",
       " 'I hurriedly dressed and ran after her said the woman.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bde2f741-bd20-4e5e-a04b-887754f82d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' two women were fighting over a child.', 'he is my child leave him alone cried the lady in the red sari.', 'the poor child was too young to speak.no he is mine cried the woman in the green sari.soon a crowd gathered.the village elders took the quarreling women to a wise man.', 'the village wise man asked the lady in the red sari what do you have to sayhe is my child sir.', 'i was bathing in the river and had left my son on the bank.', 'this woman lifted my child and ran away.', 'i hurriedly dressed and ran after her said the woman.']\n",
      "---\n",
      "[' Two women were fighting over a child.', 'He is my child leave him alone cried the lady in the red sari.', 'The poor child was too young to speak.No he is mine cried the woman in the green sari.Soon a crowd gathered.The village elders took the quarreling women to a wise man.', 'The village wise man asked the lady in the red sari What do you have to sayHe is my child Sir.', 'I was bathing in the river and had left my son on the bank.', 'This woman lifted my child and ran away.', 'I hurriedly dressed and ran after her said the woman.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "print(stemmed_tokens)\n",
    "print(\"---\")\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "lemmatize = WordNetLemmatizer()\n",
    "lemmatize_token = [lemmatize.lemmatize(word) for word in filtered_tokens]\n",
    "print(lemmatize_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "431034c5-afe2-44ed-b610-a7db0604b8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      "  0 0 0 0 0 1 0 0]]\n",
      "{'two women': 66, 'women were': 77, 'were fighting': 71, 'fighting over': 15, 'over child': 37, 'he is': 20, 'is my': 26, 'my child': 33, 'child leave': 7, 'leave him': 28, 'him alone': 22, 'alone cried': 1, 'cried the': 10, 'the lady': 53, 'lady in': 27, 'in the': 24, 'the red': 56, 'red sari': 42, 'the poor': 54, 'poor child': 38, 'child was': 9, 'was too': 70, 'too young': 64, 'young to': 79, 'to speak': 62, 'speak no': 50, 'no he': 35, 'is mine': 25, 'mine cried': 32, 'the woman': 59, 'woman in': 74, 'the green': 52, 'green sari': 17, 'sari soon': 45, 'soon crowd': 49, 'crowd gathered': 11, 'gathered the': 16, 'the village': 58, 'village elders': 67, 'elders took': 14, 'took the': 65, 'the quarreling': 55, 'quarreling women': 39, 'women to': 76, 'to wise': 63, 'wise man': 73, 'village wise': 68, 'man asked': 31, 'asked the': 4, 'sari what': 46, 'what do': 72, 'do you': 12, 'you have': 78, 'have to': 19, 'to sayhe': 61, 'sayhe is': 47, 'child sir': 8, 'was bathing': 69, 'bathing in': 5, 'the river': 57, 'river and': 43, 'and had': 2, 'had left': 18, 'left my': 29, 'my son': 34, 'son on': 48, 'on the': 36, 'the bank': 51, 'this woman': 60, 'woman lifted': 75, 'lifted my': 30, 'child and': 6, 'and ran': 3, 'ran away': 41, 'hurriedly dressed': 23, 'dressed and': 13, 'ran after': 40, 'after her': 0, 'her said': 21, 'said the': 44}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True,ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(stemmed_tokens)\n",
    "print(X.toarray()[:1])\n",
    "print(vectorizer.vocabulary_) # index  # Problem of sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b748ed9-3ae6-4711-a82b-05fc394fc681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.30063438 0.34320089 0.39529808 0.34320089 0.39529808\n",
      "  0.60126876 0.         0.         0.        ]]\n",
      "{'child': 1, 'is': 3, 'my': 4, 'the': 6, 'in': 2, 'sari': 5, 'to': 7, 'woman': 9, 'wise': 8, 'and': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1),max_features=10)  # Here also we have n gram is there\n",
    "X = tfidf_vectorizer.fit_transform(stemmed_tokens)\n",
    "print(X.toarray()[:2])\n",
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a3b94a-c30c-42a0-b91b-8a46e0a0a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "\n",
    "# Z = pd.DataFrame(table_references.keys()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e581c5-1124-4d39-8d2c-768b25efa978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d53e50-05ba-4aa5-af28-c84ce719dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
      "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
      " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
      "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
      "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
      " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
      " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
      " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
      " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
      "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
      " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
      "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
      "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
      " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
      "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
      "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = \"One Peice Luffy Will Become King of Pirate.\"\n",
    "\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Create training data\n",
    "sentences = [tokens]\n",
    "\n",
    "# Train a CBOW Word2Vec model\n",
    "model_cbow = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "# Find vector representation for a word\n",
    "vector = model_cbow.wv['Pirate']\n",
    "print(vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4a6e3c-826e-487b-9111-fc89517f96b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('King', 0.06797593832015991),\n",
       " ('One', 0.03364057093858719),\n",
       " ('Will', 0.009391162544488907),\n",
       " ('Become', 0.0045030261389911175),\n",
       " ('.', -0.010839177295565605),\n",
       " ('of', -0.023671656847000122),\n",
       " ('Luffy', -0.11410722136497498),\n",
       " ('Peice', -0.11555545777082443)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cbow.wv.most_similar('Pirate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f88f7ea0-74fe-46ba-9394-b7f1d09a5911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03364058"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cbow.wv.similarity(\"Pirate\",\"One\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c8473c5-6478-4d54-afd7-9f30a6e684aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=model_cbow.wv['Pirate']-model_cbow.wv['King']+model_cbow.wv['Luffy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db09e376-c39d-4338-b8cf-228b90ae5ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('King', 0.7362772226333618),\n",
       " ('Luffy', 0.7067073583602905),\n",
       " ('Will', 0.10608167201280594),\n",
       " ('of', 0.08927716314792633),\n",
       " ('One', 0.05906924977898598),\n",
       " ('Peice', -0.006407230626791716),\n",
       " ('Become', -0.008049077354371548),\n",
       " ('Pirate', -0.02914588712155819),\n",
       " ('.', -0.06814851611852646)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cbow.wv.most_similar([vec])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
